---
id: fallback-handoff
sidebar_label: Fallback and Human Handoff
title: Fallback and Human Handoff
---

Even if you design your bot perfectly, users will inevitably say things to your
assistant that you did not anticipate. In these cases, your assistant will fail,
and it's important you ensure it does so gracefully.

## Concepts

### Fallback Actions

Sometimes you want to revert to a fallback action, such as replying,
`"Sorry, I didn't understand that"`. You can handle fallback cases by adding appropriate
rules. Rasa Open Source comes with two default implementations for handling these
fallbacks.
In addition, you can also use [Custom Actions](./actions.mdx#custom-actions) to run any
custom code.

#### `FallbackClassifier`

Although Rasa's [Intent Classifier](./components/intent-classifiers.mdx) will
generalize to unseen messages, some
messages might receive a low classification confidence.
To handle messages with low confidence, we recommend adding the
[FallbackClassifier](./components/intent-classifiers.mdx#fallbackclassifier) to your NLU pipeline:

```yaml
pipeline:
# other components
- name: FallbackClassifier
  confidence_threshold: 0.7
```

The [FallbackClassifier](./components/intent-classifiers.mdx#fallbackclassifier) will
predict the intent `nlu_fallback` when all other intent predictions fall below
the configured confidence threshold. You can then write a rule
for what the bot should do when `nlu_fallback` is predicted. Alternatively,
you can use Two-Stage-Fallback (see next section).


### Two-Stage-Fallback

Two-Stage-Fallback handles low NLU confidence in multiple stages
by trying to disambiguate the user input.


To make use of it, add `FallbackClassifier` to 
your pipeline (see above) and the [RulePolicy](./policies.mdx#rule-policy) to your policy configuration:

```yaml
policies:
# other policies
- RulePolicy
```

You'll also need to add the
`out_of_scope` intent to your [Domain](./domain.mdx).
When users send messages with
the intent `out_of_scope` during the first or second stage of fallback (e.g. by pressing a button),
Rasa Open Source will know that the users denied the given intent suggestions.

#### Usage

- If an NLU prediction has a low confidence score, the user is asked to affirm
  the classification of the intent.  (Default action:
  `action_default_ask_affirmation`)

    - If they affirm by sending a message with high NLU confidence (e.g. by pressing
      a button), the story continues as if the intent was classified
      with high confidence from the beginning.
    - If they deny by sending a message with the intent `out_of_scope`, the user is
      asked to rephrase their message.

- Rephrasing  (default action: `action_default_ask_rephrase`)

    - If the classification of the rephrased intent was confident, the story
      continues as if the user had this intent from the beginning.
    - If the rephrased intent was not classified with high confidence, the user
      is asked to affirm the classified intent.

- Second affirmation  (default action: `action_default_ask_affirmation`)

    - If they affirm by sending a message with high NLU confidence (e.g. by pressing
      a button), the story continues as if the user had this intent from the beginning.
    - If the user denies by sending a message with the intent `out_of_scope`, the
      original intent is classified as the specifies `deny_suggestion_intent_name`,
      and an ultimate fallback action `fallback_nlu_action_name` is
      triggered (e.g. a handoff to a human).

Rasa Open Source provides default implementations for
`action_default_ask_affirmation` and `action_default_ask_rephrase`.
The default implementation of `action_default_ask_rephrase` utters
the response `utter_ask_rephrase`, so make sure to specify this
response in your domain file.
The implementation of both actions can be overwritten with
[Custom Actions](./actions.mdx#custom-actions).

To use the `Two-Stage-Fallback` for messages with low NLU confidence, add the
following [Rule](./rules.mdx) to your training data. This rule will make sure that the
`Two-Stage-Fallback` will be activated whenever a message is received with
low classification confidence.

```yaml
rules:
- rule: Implementation of the Two-Stage-Fallback
  steps:
  - intent: nlu_fallback
  - action: two_stage_fallback
  - active_loop: two_stage_fallback
```

### Handling Low Core Confidence

As users might send unexpected messages,
it is possible that their behavior will lead them down unknown conversation paths.
Rasa's machine learning policies such as the [TED Policy](./policies.mdx#ted-policy)
are optimized to handle these unknown paths.

To handle cases where even the machine learning policies can't predict the
next action with high confidence, configure the 
[Rule Policy](./policies.mdx#rule-policy) to predict a
default action if no [Policy](./policies.mdx) has a next action prediction with
confidence above a configurable threshold.

You can configure the action that is run in case low of Core confidence as well as
the corresponding confidence threshold as follows:

```yaml
policies:
- name: RulePolicy
  # Confidence threshold for the `core_fallback_action_name` to apply.
  # The action will apply if no other action was predicted with
  # a confidence >= core_fallback_threshold
  core_fallback_threshold: 0.4
  core_fallback_action_name: "action_default_fallback"
  enable_fallback_prediction: True
```

:::note

If you do not want the `Rule Policy` to predict a default action in case of low Core
confidence, specify `enable_fallback_prediction: False` in the configuration of the
policy.
:::


`action_default_fallback` is a default action in Rasa Open Source that sends the
`utter_default` response to the user. Make sure to specify
the `utter_default` in your domain file. It will also revert back to the
state of the conversation before the user message that caused the
fallback, so it will not influence the prediction of future actions.

You can also create your own custom action to use as a fallback (see
[Custom Actions](./actions.mdx#custom-actions) for more info on custom actions).
The following snippet is an implementation of a custom action which does the same as
`action_default_fallback` but dispatches a different template
`my_custom_fallback_template`:

```python
from typing import Any, Text, Dict, List

from rasa_sdk import Action, Tracker
from rasa_sdk.events import UserUtteranceReverted
from rasa_sdk.executor import CollectingDispatcher

class ActionDefaultFallback(Action):
    """Executes the fallback action and goes back to the previous state
    of the dialogue"""

    def name(self) -> Text:
        return ACTION_DEFAULT_FALLBACK_NAME

    async def run(
        self,
        dispatcher: CollectingDispatcher,
        tracker: Tracker,
        domain: Dict[Text, Any],
    ) -> List[Dict[Text, Any]]:
        dispatcher.utter_message(template="my_custom_fallback_template")

        # Revert user message which led to fallback.
        return [UserUtteranceReverted()]
```


<img alt="Intent Mappings" src={useBaseUrl("/img/intent_mappings.png")} width="240" />

### Out of scope intent

It is good practice to also handle questions you know your users may ask, 
but for which you haven't necessarily implemented a user goal yet.

You can define an `out_of_scope` intent to handle generic out of scope requests, like “I'm hungry” and have
the bot respond with a default message like “Sorry, I can't handle that request” by writing a rule with the
`out_of_scope` intent in it.

Going one step further, if you observe your users asking for certain things that you'll
want to turn into a user goal in future, you can handle these as separate intents, to let
the user know you've understood their message, but don't have a solution quite yet. For example,
if the user asks “I want to apply for a job at Rasa”, we can then reply with
“I understand you're looking for a job, but I'm afraid I can't handle that skill yet.”

### Human Handoff

As part of your fallback action, you may want the bot to hand over to a human agent
e.g. as the final action in Two-Stage-Fallback, or when the user explicitly asks 
for a human. A straightforward way to achieve human handoff is to configure your 
[messaging or voice channel](messaging-and-voice-channels.mdx) to switch
which host it listens to based on a specific bot or user message.

For example, as the final action of Two-Stage-Fallback, the bot could ask the user, 
"Would you like to be transferred to a human assistant?" and if they say yes, the
bot sends a message with a specific payload like
e.g. "handoff_to_human" to the channel. When the channel sees this message, it stops listening
to the Rasa server, and sends a message to the human channel with the transcript
of the chat conversation up to that point. 

The implementation for handing off to a human from the front end will depend on which
channel you're using. You can
see an example implementation using an adaption of the [chatroom](https://github.com/scalableminds/chatroom) channel 
in the [Financial Demo](https://github.com/RasaHQ/financial-demo) and 
[Helpdesk-Assistant](https://github.com/RasaHQ/helpdesk-assistant)
starterpacks.


## Data

You'll need to define rules for fallback and out-of-scope situations.
You'll only need NLU training data for out-of-scope intents. 
For human handoff, no training data is needed unless you want 
a seperate rule for handing off to a human vs. Two-Stage-Fallback,
or if you want to create a `human_handoff` intent that can be predicted directly.

### NLU Training Data

You should add any known out-of-scope requests to the training
data for the `out_of_scope` intent or the specific out-of-scope intents, for example:

```yaml
nlu:
- intent: out_of_scope
  examples: |
    - I want to order food
    - What is 2 + 2?
    - Who's the US President?

- intent: ask_job
  examples: |
    - I need a job
    - can I apply for a job here
    - do you have open positions
```

As with every intent, you should source the majority of your examples 
from real conversations. This is especially important for out-of-scope intents
since false positives for these intents can lead to a bad user experience.

### Rules
#### Rules for Messages with Low Confidence

When you add the [FallbackClassifier](./components/intent-classifiers.mdx#fallbackclassifier)  to
your NLU pipeline, you can treat
messages with low classification confidence as any other intent. The following
[Rule](./rules.mdx) will ask the user to rephrase when they send a message that is
classified with low confidence:

```yaml
rules:
- rule: Ask the user to rephrase whenever they send a message with low NLU confidence
  steps:
  - intent: nlu_fallback
  - action: utter_please_rephrase
```

Using [Rules](./rules.mdx) or [Stories](./stories.mdx) you can implement any desired
fallback behavior.

#### Rules for Two-Stage Fallback

To use the `Two-Stage-Fallback` for messages with low NLU confidence, add the
following [Rule](./rules.mdx) to your training data. This rule will make sure that the
`Two-Stage-Fallback` will be activated whenever a message is received with
low classification confidence.

```yaml
rules:
- rule: Implementation of the Two-Stage-Fallback
  steps:
  - intent: nlu_fallback
  - action: two_stage_fallback
  - form: two_stage_fallback
```


#### Rules for out-of-scope requests 

You need to write rules for what should happen for 
each type of out-of-scope request:

```yaml
rules:
- rule: out of scope
  steps:
  - intent: out_of_scope
  - action: utter_out_of_scope

- rule: out of scope job
  steps:
  - intent: ask_job
  - action: utter_job_not_handled
```

The above example uses single-turn interactions, but 
you can write a rule with whichever action or actions you'd like for each out-of-scope scenario.

### Responses

You'll need to define fallback and out-of-scope responses in our domain. 
For example, assuming you're using the default fallback actions and the
two out-of-scope intents defined above:

```yaml
responses:
  utter_out_of_scope:
  - text: Sorry, I can't handle that request.
  utter_job_not_handled:
  - text: I understand you're looking for a job, but I'm afraid I can't handle that request yet.
  utter_ask_rephrase:
  - text: I'm sorry, I didn't quite understand that. Could you rephrase?
  utter_default:
  - text: 
```

## Putting it all together

It's up to you how you want your assistant to act in a fallback or handoff
situation. You might want to use one or more of the options
described above Here's a summary of changes you need to make for each:

For single stage NLU fallback:
  - [ ] Add `FallbackClassifier` to your pipeline in `config.yml`
  - [ ] Define a rule for the `nlu_fallback` intent

For known out-of-scope intents:
  - [ ] Add training examples for each out-of-scope intent to your NLU data
  - [ ] Define rules for each out-of-scope intent

For Two-Stage Fallback:
  - [ ] Add `FallbackClassifier` to your pipeline in `config.yml`
  - [ ] Define a rule for the `nlu_fallback` intent that triggers the `two_stage_fallback` action
  - [ ] Define an out-of-scope intent in your domain

For handling low core confidence:
  - [ ] Configure the `RulePolicy` for core fallback in `config.yml`
  - [ ] Optionally customize the fallback action you configure

For handing off to a human:
  - [ ] Configure your front end to switch hosts
  - [ ] Write a custom action (which could be your fallback action) to send the handoff payload
  - [ ] Add a rule for triggering handoff (if not part of fallback)
